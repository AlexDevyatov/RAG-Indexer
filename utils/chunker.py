"""
–ú–æ–¥—É–ª—å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–≥–æ —á–∞–Ω–∫–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞.
–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ —Å –∑–∞–¥–∞–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º.
"""

from typing import List, Optional


# –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –¥–ª—è —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–≥–æ —á–∞–Ω–∫–∏–Ω–≥–∞ (–æ—Ç –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã—Ö –∫ –º–µ–ª–∫–∏–º)
DEFAULT_SEPARATORS = ["\n\n", "\n", ". ", " "]


def count_tokens_approx(text: str) -> int:
    """
    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ,
    –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ ‚âà 2-3 —Å–∏–º–≤–æ–ª–∞).
    –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 3.5 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω.
    
    Args:
        text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
        
    Returns:
        –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
    """
    return len(text) // 3


def split_by_separator(text: str, separator: str) -> List[str]:
    """
    –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è.
    
    Args:
        text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
        separator: —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        
    Returns:
        —Å–ø–∏—Å–æ–∫ —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞
    """
    if not separator:
        return list(text)
    
    parts = text.split(separator)
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –æ–±—Ä–∞—Ç–Ω–æ –∫ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π)
    result = []
    for i, part in enumerate(parts):
        if i < len(parts) - 1:
            result.append(part + separator)
        else:
            result.append(part)
    
    return [p for p in result if p]  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏


def recursive_chunk(
    text: str,
    chunk_size: int = 512,
    chunk_overlap: int = 50,
    separators: Optional[List[str]] = None
) -> List[str]:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞.
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ç–µ–∫—É—â–µ–º—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é
    2. –ï—Å–ª–∏ —á–∞—Å—Ç—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è - —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é
    3. –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞—Å—Ç–∏ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    4. –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
    
    Args:
        text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
        chunk_size: —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö
        chunk_overlap: —Ä–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –≤ —Ç–æ–∫–µ–Ω–∞—Ö
        separators: —Å–ø–∏—Å–æ–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π (–æ—Ç –∫—Ä—É–ø–Ω—ã—Ö –∫ –º–µ–ª–∫–∏–º)
        
    Returns:
        —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤
    """
    if separators is None:
        separators = DEFAULT_SEPARATORS.copy()
    
    # –ë–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π: —Ç–µ–∫—Å—Ç –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    if count_tokens_approx(text) <= chunk_size:
        return [text.strip()] if text.strip() else []
    
    # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
    if not separators:
        return force_split(text, chunk_size, chunk_overlap)
    
    # –ë–µ—Ä—ë–º —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    separator = separators[0]
    remaining_separators = separators[1:]
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
    parts = split_by_separator(text, separator)
    
    chunks = []
    current_chunk = ""
    
    for part in parts:
        part_tokens = count_tokens_approx(part)
        current_tokens = count_tokens_approx(current_chunk)
        
        # –ï—Å–ª–∏ —á–∞—Å—Ç—å —Å–∞–º–∞ –ø–æ —Å–µ–±–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è - —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º
        if part_tokens > chunk_size:
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ –µ—Å–ª–∏ –µ—Å—Ç—å
            if current_chunk.strip():
                chunks.append(current_chunk.strip())
                current_chunk = ""
            
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å
            sub_chunks = recursive_chunk(
                part, chunk_size, chunk_overlap, remaining_separators
            )
            chunks.extend(sub_chunks)
            continue
        
        # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —á–∞—Å—Ç–∏ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫
        if current_tokens + part_tokens > chunk_size and current_chunk.strip():
            chunks.append(current_chunk.strip())
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
            overlap_text = get_overlap(current_chunk, chunk_overlap)
            current_chunk = overlap_text + part
        else:
            current_chunk += part
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
    if current_chunk.strip():
        chunks.append(current_chunk.strip())
    
    return chunks


def force_split(text: str, chunk_size: int, chunk_overlap: int) -> List[str]:
    """
    –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º –∫–æ–≥–¥–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç.
    
    Args:
        text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
        chunk_size: —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä –≤ —Ç–æ–∫–µ–Ω–∞—Ö
        chunk_overlap: —Ä–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –≤ —Ç–æ–∫–µ–Ω–∞—Ö
        
    Returns:
        —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –≤ —Å–∏–º–≤–æ–ª—ã (–ø—Ä–∏–º–µ—Ä–Ω–æ)
    char_size = chunk_size * 3
    char_overlap = chunk_overlap * 3
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + char_size
        chunk = text[start:end].strip()
        
        if chunk:
            chunks.append(chunk)
        
        start = end - char_overlap
    
    return chunks


def get_overlap(text: str, overlap_tokens: int) -> str:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Ç–æ–∫–µ–Ω–æ–≤).
    
    Args:
        text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        overlap_tokens: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
        
    Returns:
        —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –≤ —Å–∏–º–≤–æ–ª—ã
    overlap_chars = overlap_tokens * 3
    
    if len(text) <= overlap_chars:
        return text
    
    return text[-overlap_chars:]


def chunk_document(
    text: str,
    source: str,
    chunk_size: int = 512,
    chunk_overlap: int = 50
) -> List[dict]:
    """
    –ß–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        text: —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
        source: –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        chunk_size: —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö
        chunk_overlap: —Ä–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –≤ —Ç–æ–∫–µ–Ω–∞—Ö
        
    Returns:
        —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —á–∞–Ω–∫–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    chunks = recursive_chunk(text, chunk_size, chunk_overlap)
    
    result = []
    for i, chunk in enumerate(chunks):
        result.append({
            "text": chunk,
            "source": source,
            "chunk_index": i,
            "total_chunks": len(chunks),
            "token_count_approx": count_tokens_approx(chunk)
        })
    
    return result


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    sample_text = """
    Python ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π 
    —Å—Ç—Ä–æ–≥–æ–π —Ç–∏–ø–∏–∑–∞—Ü–∏–µ–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é.
    
    –Ø–∑—ã–∫ —Å–æ–∑–¥–∞–Ω –≤ –∫–æ–Ω—Ü–µ 1980-—Ö –≥–æ–¥–æ–≤ –ì–≤–∏–¥–æ –≤–∞–Ω –†–æ—Å—Å—É–º–æ–º, –ø–µ—Ä–≤–∞—è –≤–µ—Ä—Å–∏—è –≤—ã—à–ª–∞ –≤ 1991 –≥–æ–¥—É.
    
    –û—Å–Ω–æ–≤–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ Python:
    - –ü—Ä–æ—Å—Ç–æ–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
    - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é
    - –ë–æ–≥–∞—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
    - –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    
    Python —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤:
    - –í–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ (Django, Flask)
    - –ù–∞—É–∫–µ –æ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ (NumPy, Pandas, TensorFlow)
    - –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏ —Å–∫—Ä–∏–ø—Ç–∏–Ω–≥–µ
    - –†–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏–≥—Ä
    - –°–∏—Å—Ç–µ–º–Ω–æ–º –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–∏
    """
    
    print("üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–µ—Ä–∞\n")
    print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(sample_text)} —Å–∏–º–≤–æ–ª–æ–≤, ~{count_tokens_approx(sample_text)} —Ç–æ–∫–µ–Ω–æ–≤")
    
    chunks = chunk_document(sample_text, "test.txt", chunk_size=100, chunk_overlap=20)
    
    print(f"\nüì¶ –ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}\n")
    
    for chunk in chunks:
        print(f"--- –ß–∞–Ω–∫ {chunk['chunk_index'] + 1}/{chunk['total_chunks']} ---")
        print(f"üìä ~{chunk['token_count_approx']} —Ç–æ–∫–µ–Ω–æ–≤")
        print(f"üìÑ –¢–µ–∫—Å—Ç: {chunk['text'][:100]}...")
        print()
